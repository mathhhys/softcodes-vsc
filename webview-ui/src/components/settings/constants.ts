import {
	type ProviderName,
	type ModelInfo,
	anthropicModels,
	bedrockModels,
	claudeCodeModels,
	deepSeekModels,
	geminiModels,
	geminiCliModels,
	mistralModels,
	openAiNativeModels,
	vertexModels,
	xaiModels,
	groqModels,
	chutesModels,
} from "@roo-code/types"

import { fireworksModels, cerebrasModels } from "@roo/api"

export const MODELS_BY_PROVIDER: Partial<Record<ProviderName, Record<string, ModelInfo>>> = {
	anthropic: anthropicModels,
	"claude-code": claudeCodeModels,
	bedrock: bedrockModels,
	deepseek: deepSeekModels,
	gemini: geminiModels,
	"gemini-cli": geminiCliModels,
	fireworks: fireworksModels,
	mistral: mistralModels,
	"openai-native": openAiNativeModels,
	vertex: vertexModels,
	xai: xaiModels,
	groq: groqModels,
	chutes: chutesModels,
	cerebras: cerebrasModels,
}

export const PROVIDERS = [
	{ value: "openrouter", label: "Softcodes" },
	{ value: "anthropic", label: "Anthropic" },
	{ value: "fireworks", label: "Fireworks" },
	{ value: "claude-code", label: "Claude Code" },
	{ value: "gemini", label: "Google Gemini" },
	{ value: "gemini-cli", label: "Gemini CLI" },
	{ value: "deepseek", label: "DeepSeek" },
	{ value: "openai-native", label: "OpenAI" },
	{ value: "openai", label: "OpenAI Compatible" },
	{ value: "vertex", label: "GCP Vertex AI" },
	{ value: "bedrock", label: "Amazon Bedrock" },
	{ value: "glama", label: "Glama" },
	{ value: "vscode-lm", label: "VS Code LM API" },
	{ value: "mistral", label: "Mistral" },
	{ value: "lmstudio", label: "LM Studio" },
	{ value: "ollama", label: "Ollama" },
	{ value: "unbound", label: "Unbound" },
	{ value: "requesty", label: "Requesty" },
	{ value: "human-relay", label: "Human Relay" },
	{ value: "xai", label: "xAI (Grok)" },
	{ value: "groq", label: "Groq" },
	{ value: "chutes", label: "Chutes AI" },
	{ value: "cerebras", label: "Cerebras" },
	{ value: "litellm", label: "LiteLLM" },
] // .sort((a, b) => a.label.localeCompare(b.label))
